import multiprocessing
from typing import Union, List, Tuple

import numpy as np
from batchgenerators.utilities.file_and_folder_operations import subfiles, isfile, join

from nnunetv2.configuration import default_num_processes
from nnunetv2.evaluation.evaluate_predictions import save_summary_json, region_or_label_to_mask, compute_tp_fp_fn_tn
from nnunetv2.evaluation.metrics import ALL_METRICS
from nnunetv2.evaluation.surface_dice_similarity import evaluate_case_sdc
from nnunetv2.imageio.base_reader_writer import BaseReaderWriter
from nnunetv2.utilities.json_export import recursive_fix_for_json_export
from surface_distance import metrics


def compute_metrics_on_folder(folder_ref: str, folder_pred: str, output_file: str,
                              image_reader_writer: BaseReaderWriter,
                              file_ending: str,
                              regions_or_labels: Union[List[int], List[Union[int, Tuple[int, ...]]]],
                              ignore_label: int = None,
                              num_processes: int = default_num_processes,
                              chill: bool = True,
                              voxel_spacing: Union[List[float], Tuple[float, ...]] = [1.0, 1.0, 1.0]) -> dict:
    """
    output_file must end with .json; can be None
    """
    if output_file is not None:
        assert output_file.endswith('.json'), 'output_file should end with .json'
    files_pred = subfiles(folder_pred, suffix=file_ending, join=False)
    files_ref = subfiles(folder_ref, suffix=file_ending, join=False)
    if not chill:
        present = [isfile(join(folder_pred, i)) for i in files_ref]
        assert all(present), "Not all files in folder_ref exist in folder_pred"
    files_ref = [join(folder_ref, i) for i in files_pred]
    files_pred = [join(folder_pred, i) for i in files_pred]
    # print(files_pred)
    with multiprocessing.get_context("spawn").Pool(num_processes) as pool:
        # for i in list(zip(files_ref, files_pred, [image_reader_writer] * len(files_pred), [regions_or_labels] * len(files_pred), [ignore_label] * len(files_pred))):
        #     compute_metrics(*i)
        results = pool.starmap(
            compute_metrics,
            list(zip(files_ref, files_pred, [image_reader_writer] * len(files_pred), [regions_or_labels] * len(files_pred),
                     [ignore_label] * len(files_pred), [voxel_spacing] * len((files_pred))))
        )

    # mean metric per class
    metric_list = list(results[0]['metrics'][regions_or_labels[0]].keys())
    means = {}
    for r in regions_or_labels:
        means[r] = {}
        for m in metric_list:
            means[r][m] = np.nanmean([i['metrics'][r][m] for i in results])

    # foreground mean
    foreground_mean = {}
    for m in metric_list:
        values = []
        for k in means.keys():
            if k == 0 or k == '0':
                continue
            values.append(means[k][m])
        foreground_mean[m] = np.mean(values)

    [recursive_fix_for_json_export(i) for i in results]
    recursive_fix_for_json_export(means)
    recursive_fix_for_json_export(foreground_mean)
    result = {'metric_per_case': results, 'mean': means, 'foreground_mean': foreground_mean}
    if output_file is not None:
        save_summary_json(result, output_file)
    return result

def compute_metrics(reference_file: str, prediction_file: str, image_reader_writer: BaseReaderWriter,
                    labels_or_regions: Union[List[int], List[Union[int, Tuple[int, ...]]]],
                    ignore_label: int = None,
                    voxel_spacing: Union[List[float], Tuple[float, ...]] = [1.0, 1.0, 1.0]) -> dict:
    # load images
    seg_ref, seg_ref_dict = image_reader_writer.read_seg(reference_file)
    seg_pred, seg_pred_dict = image_reader_writer.read_seg(prediction_file)

    ignore_mask = seg_ref == ignore_label if ignore_label is not None else None

    results = {}
    results['reference_file'] = reference_file
    results['prediction_file'] = prediction_file
    results['metrics'] = {}
    for r in labels_or_regions:
        results['metrics'][r] = {}
        mask_ref = region_or_label_to_mask(seg_ref, r)
        mask_pred = region_or_label_to_mask(seg_pred, r)
        tp, fp, fn, tn = compute_tp_fp_fn_tn(mask_ref, mask_pred, ignore_mask)

        if tp + fp + fn == 0:
            results['metrics'][r]['Dice'] = 1
            results['metrics'][r]['IoU'] = 0
            results['metrics'][r]['SDC'] = 1
        else:
            results['metrics'][r]['Dice'] = 2 * tp / (2 * tp + fp + fn)
            results['metrics'][r]['IoU'] = tp / (tp + fp + fn)
            surface_distances = metrics.compute_surface_distances(
                np.squeeze(mask_ref, axis=0), np.squeeze(mask_pred, axis=0), voxel_spacing
            )
            sdc = metrics.compute_surface_dice_at_tolerance(
                surface_distances,
                tolerance_mm=1)
            # results['metrics'][r]['HD95'] = ALL_METRICS['Hausdorff Distance 95'](mask_pred, mask_ref, voxel_spacing=voxel_spacing)
            results['metrics'][r]['SDC'] = sdc

        results['metrics'][r]['FP'] = fp
        results['metrics'][r]['TP'] = tp
        results['metrics'][r]['FN'] = fn
        results['metrics'][r]['TN'] = tn
        results['metrics'][r]['n_pred'] = fp + tp
        results['metrics'][r]['n_ref'] = fn + tp
    return results